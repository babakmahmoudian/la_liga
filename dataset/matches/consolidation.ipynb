{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f8f476-8b96-4202-a703-35cf5ec31fa3",
   "metadata": {},
   "source": [
    "All data downloaded from https://www.football-data.co.uk/spainm.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0059f8-96e0-4a3d-8819-f65492287ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5380469c-b0ca-4390-9e0e-57121bf260b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_name = 'primera'\n",
    "league_years = [f\"{year}_{year+1}\" for year in range(2017, 2023)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7d12778",
   "metadata": {},
   "source": [
    "# Reading the dataset files\n",
    "Reading all the data from files into separate dataframes; which will later be consolidated into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adb0464-f019-483e-a5c4-6ac084044d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will hold every single separate dataframe\n",
    "df_list = dict()\n",
    "\n",
    "# Going through all the files for each league division\n",
    "for league_year in league_years:\n",
    "    dataset_file = f\"./initial_ds/{league_name}_{league_year}.csv\"\n",
    "    # Reading the league's data from the file\n",
    "    cur_df = pd.read_csv(dataset_file)\n",
    "    # Removing the rows which contain only Null values\n",
    "    cur_df = cur_df.dropna(axis='index', how=\"all\")\n",
    "    # Removing the columns which contain only Null values\n",
    "    cur_df = cur_df.dropna(axis=\"columns\", how='all')\n",
    "    # Adding the season as a new column\n",
    "    cur_df.insert(1, 'season', league_year, True)\n",
    "    df_list[league_year] = cur_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "097c3e18",
   "metadata": {},
   "source": [
    "# Merging the dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47f86e59",
   "metadata": {},
   "source": [
    "Getting the accululated list of all the columns available in all dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf318df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = dict()\n",
    "for df_name, df_table in df_list.items():\n",
    "    for col in df_table.columns:\n",
    "        all_cols[col] = all_cols[col] + [df_name] if col in all_cols.keys() else [df_name]\n",
    "\n",
    "all_cols = dict(sorted(all_cols.items(), key=lambda item: len(item[1]), reverse=True))        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4c8036",
   "metadata": {},
   "source": [
    "Merging all the separate dataframes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ab83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=all_cols.keys())\n",
    "for df_season in df_list.values():\n",
    "    df = pd.concat([df, df_season], axis=0)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d21e78",
   "metadata": {},
   "source": [
    "# Cleaning up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc950fbc",
   "metadata": {},
   "source": [
    "Getting the list of the columns that are present in all of the recent seasons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8bf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cols = []\n",
    "\n",
    "for col, seasons in all_cols.items():\n",
    "    if all([season in seasons for season in league_years]):\n",
    "        main_cols.append(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63917d38",
   "metadata": {},
   "source": [
    "Dropping all other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5ed6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[main_cols]\n",
    "\n",
    "# Dropping the division column (since they are all primera)\n",
    "df = df.drop('Div', axis='columns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0165afd1",
   "metadata": {},
   "source": [
    "## Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093020c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={\n",
    "    'Date': 'date',\n",
    "    'HomeTeam': 'home', \n",
    "    'AwayTeam': 'away',\n",
    "    'FTHG': 'home_fulltime_goals',\n",
    "    'FTAG': 'away_fulltime_goals',\n",
    "    'FTR': 'fulltime_result',\n",
    "    'HTHG': 'home_halftime_goals',\n",
    "    'HTAG': 'away_halftime_goals',\n",
    "    'HTR': 'halftime_result',\n",
    "    'HS': 'home_total_shots',\n",
    "    'AS': 'away_total_shots',\n",
    "    'HST': 'home_shots_on_target',\n",
    "    'AST': 'away_shots_on_target',\n",
    "    'HF': 'home_fouls_committed',\n",
    "    'AF': 'away_fouls_committed',\n",
    "    'HC': 'home_corners',\n",
    "    'AC': 'away_corners',\n",
    "    'HY': 'home_yellow_cards',\n",
    "    'AY': 'away_yellow_cards',\n",
    "    'HR': 'home_red_cards',\n",
    "    'AR': 'away_red_cards',\n",
    "    'B365H': 'home_win_bet365_odds',\n",
    "    'B365D': 'draw_bet365_odds',\n",
    "    'B365A': 'away_win_bet365_odds',\n",
    "    'BWH': 'home_win_betandwin_odds',\n",
    "    'BWD': 'draw_betandwin_odds',\n",
    "    'BWA': 'away_win_betandwin_odds',\n",
    "    'IWH': 'home_win_interwetten_odds',\n",
    "    'IWD': 'draw_interwetten_odds',\n",
    "    'IWA': 'away_win_interwetten_odds',\n",
    "    'PSH': 'home_win_pinnaclesports_odds',\n",
    "    'PSD': 'draw_pinnaclesports_odds',\n",
    "    'PSA': 'away_win_pinnaclesports_odds',\n",
    "    'WHH': 'home_win_williamhill_odds',\n",
    "    'WHD': 'draw_williamhill_odds',\n",
    "    'WHA': 'away_win_williamhill_odds',\n",
    "    'VCH': 'home_win_vcbet_odds',\n",
    "    'VCD': 'draw_vcbet_odds',\n",
    "    'VCA': 'away_win_vcbet_odds',\n",
    "    'PSCH': 'home_win_pinnaclesports_closing_odds',\n",
    "    'PSCD': 'draw_pinnaclesports_closing_odds',\n",
    "    'PSCA': 'away_win_pinnaclesports_closing_odds',\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82df5165",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns\n",
    "These columns refer to in-game stats and are also retrieved from other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6984c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\n",
    "    'home_total_shots',\n",
    "    'away_total_shots',\n",
    "    'home_shots_on_target',\n",
    "    'away_shots_on_target',\n",
    "    'home_fouls_committed',\n",
    "    'away_fouls_committed',\n",
    "    'home_corners',\n",
    "    'away_corners',\n",
    "    'home_yellow_cards',\n",
    "    'away_yellow_cards',\n",
    "    'home_red_cards',\n",
    "    'away_red_cards',\n",
    "], axis='columns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1af6d886",
   "metadata": {},
   "source": [
    "## Correcting the dates\n",
    "The dates are currently of type string (object). They need to be converted into DateTime.<br>\n",
    "However, before doing that, some values must be tweaked to conform to conventional date formats.<br>\n",
    "For instance:\n",
    "<ul>\n",
    "    <li>'%d/%m/99' must be converted to '%d/%m/1999'</li>\n",
    "    <li>'%d/%m/00' must be converted to '%d/%m/2000'</li>\n",
    "    <li>'%d/%m/01' must be converted to '%d/%m/2001'</li>\n",
    "    <li>...</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0960411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the required corrections in terms of RegEx\n",
    "replacements = dict(dict((f\"/{str(y).zfill(2)}$\", f\"/{2000 + y}\") for y in range(17, 24)))\n",
    "# Fixing the inconsistencies in the date columns\n",
    "df['date'] = df['date'].replace(replacements, regex=True)\n",
    "# Converting the date column from object to DateTime64\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0b89f",
   "metadata": {},
   "source": [
    "# Saving the cleaned up dataset into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60cd497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./processed_ds/matches.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "83d208b031a4a5a0824f5f0b47c0388aa3b94cdd004c2f68e4341ab470ede466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
